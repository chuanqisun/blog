---
title: The Porcelain to Come
date: 2025-10-10
keywords: ["programming", "ai", "philosophy"]
---

A recent conversation with [Pat](https://www.media.mit.edu/people/patpat/overview/), a visionary technologist at MIT, and [Phoom](https://poom.dev/), a brilliant hacker-philosopher-entrepreneur, left me unsettled. We spoke about the future of programming, but the exchange felt less like charting new territory and more like watching something slip away.

I had recently read an article on "[Comprehension Debt: The Ticking Time Bomb of LLM-Generated Code](https://codemanship.wordpress.com/2025/09/30/comprehension-debt-the-ticking-time-bomb-of-llm-generated-code/)" that validated my theory of [AI fatigue](./20240201-ai-fatigue). The author, [codemanship](https://codemanship.wordpress.com/), argues that when the speed of code generation exceeds the speed of understanding, we accrue a debt that eventually leads to bankruptcy.

The metaphor is apt, but I think the problem runs deeper than technical and cognitive debt.

## The Reductionist Trap

The world favors a reductionist view of programming as a means of production. Faster is better. Easier is better. This isn't wrong, exactly, but it's incomplete in a way that matters. Most programs lack constructs to represent the plurality of thought. We compute and reduce to a single correct answer. Even in quantum computing where multiple states coexist, we must collapse to a single reality for something useful to emerge. This leaves out a large portion of human thinking that is non-linear, parallel, divergent, holistic, unstable, and internally inconsistent.

Vibe coding rides this wave of reduction to its logical extreme. It gives people a shortcut to programs without programming. For developers who can dive into generated code and reshape it, this might be useful. I experienced this myself while "[Vibe Coding the MIT Course Catalog](./20250806-vibe-coding-mit-course-catalog)," an iterative process where I could inspect and adjust. But for non-coding people, it's shooting in the dark. They get output without insight, results without comprehension.

The optimists will say accuracy will improve as AI models advance. I believe them. But I also believe something else will decline: the will to patiently approach a problem from the ground up. Thinking will become lazy, muddy, fragmented. [Weakty](https://weakty.com/) observed in "[Our Efforts, In Part, Define Us](https://weakty.com/posts/efforts/)," that the lack of effort has led to the lack of satisfaction. When a program becomes an artifact that anyone can generate with the same prompt, the activity would feel like working on the assembly line.

## Alignment, with Yourself

Carl Jung theorized [individuation](https://www.youtube.com/watch?v=tqygSdz0Syc), the process of becoming who you actually are rather than who circumstances have shaped you to be. When people are misaligned with their true selves, they experience incompleteness and dissatisfaction. I think about this often in relation to programming. Not because I want to make grand claims about self-actualization through code, but because the feeling of misalignment is so palpable in how we talk about AI-assisted development.

Programming languages have always evolved by ascending the abstraction ladder: machine code, assembly, system programs, object-oriented paradigms, scripting languages, domain-specific languages. Each new abstraction didn't necessarily make programming easier. Instead, they redistributed effort into different cognitive spaces, moving concerns from the machine to symbols to objects to tasks.

A programmer must learn to think in each new abstraction to compose good programs. This learning process is effortful, and that effort gives us confidence that we are one with the abstraction. We can remold our software to fit our needs. We can share knowledge with other programmers who inhabit the same conceptual space. We are equipped to ascend to the next level.

It's unclear what the effort of mastering vibe coding prepares us for. I don't feel confident about modifying my generated code, no matter how much effort I put into prompt engineering. I don't feel I'm learning a new abstraction. It feels more like gambling in a casino, pulling the lever until I hit the jackpot.

## Generation, or Creation?

> What I cannot create, I do not understand.  
> -- Richard Feynman

This statement has haunted me since I started thinking seriously about AI-generated code. I'm increasingly convinced that AI programming is more like searching through other people's code than creating something new. The creation is an illusion, a parlor trick of recombination.

From a constructivist learning theory perspective, programming should be a perfect learning experience. The programmer assembles code through trial and error, gaining understanding through reflection. AI short-circuits this process by feeding knowledge directly to the user. This is the core of my hypothesis on "[AI fatigue](./20240201-ai-fatigue)," where validating a solution without deriving it by hand causes extreme cognitive dissonance. The damage of this lack of understanding hasn't fully manifested yet, but I suspect we're producing a generation of people who can't think independently, a kind of thought slavery to AI.

Consider ChatGPT's [study mode](https://openai.com/index/chatgpt-study-mode/), which educators and students have embraced. Students still passively wait for AI to assess their knowledge, challenge them with questions, nudge them toward the right direction. They lose the ability to self-assess, self-challenge, self-correct. I also believe that we are piling technology onto a shaky foundation that is our educational system since the industrial age. If homework is assigned such that students prefer cheating with AI, the design of the homework is broken. We need to think about creating engagement with intrinsic motivation, not tasks to fulfill.

> People don't get ideas; they make them.  
> -- Mitchel Resnick

> The role of the teacher is to create the conditions for invention rather than provide ready-made knowledge.  
> -- Seymour Papert

> I cannot think without writing.  
> -- Jean Piaget

Words from the visionaries have echoed for decades. Is AI bringing us closer to or further from their ideals?

## Augmentation and Symbiosis

I think J.C.R. Licklider's "[Man-Computer Symbiosis](http://groups.csail.mit.edu/medg/people/psz/Licklider.html)" and Douglas Engelbart's "[Augmenting Human Intellect](https://www.dougengelbart.org/pubs/papers/scanned/Doug_Engelbart-AugmentingHumanIntellect.pdf)" are two of the most misunderstood visions in today's technology discourse. Both believed in symbiosis as a way to help humans evolve and adapt in pace with technology, and that technology would in turn reward us with more skills to extend our activities.

Licklider wrote:

> The human operators are responsible mainly for functions that it proved infeasible to automate. Such systems [...] are not symbiotic systems. They are "semi-automatic" systems, systems that started out to be fully automatic but fell short of the goal.

Christina Engelbart, [reflecting on her father's work](https://www.dougengelbart.org/content/view/183/153/), noted:

> [...] with the explosive emergence of digital technology, the technical elements would shoot way ahead of the non-technical and cause a trend toward automating rather than augmenting peoples' activities. It would be necessary, therefore, to accelerate the co-evolutionary process, which means purposefully focusing in on the potential of human processes in concert with technological possibilities, with a special focus on those that serve to improve our collective capabilities.

But technologies in our time have distorted these ideas into fearless enhancement of human body and brain, driven by capitalistic and individualistic pursuit of efficiency and productivity. In current AI discourse, I don't hear enough about "human processes" or "collective capabilities." Instead, we're sold the idea that full automation may lead to universal basic income. It's a world void of human interests but filled with economic incentives. That kind of augmentation is amputation.

## The Metaphor Problem

Programming as conquering the world is a terrible metaphor, yet it's preached everywhere. We started with AI defeating humans in chess and Go. AI labs release models that compete for medals in mathematics, as reported in [Nature](https://www.nature.com/articles/d41586-025-02343-x). We call benchmarks "[Humanity's Last Exam](https://agi.safe.ai/)", framing AI against humanity. Our fantasy toward AI is plagued with dystopian visions of takeover, warfare, automation, hallmarked by the "high tech low life" world of cyberpunk.

What if we chose different metaphors? What if programming were **cartography**: visualizing known territories throughout history and lineage, highlighting frontiers according to the zone of proximal development, expanding territory by documenting new learning?

What if programming were **gardening**: planting seeds of small ideas, caring for them by making connections and developing constraints, cross-breeding concepts, harvesting more ideas that lead to action plans?

What if programming were **sculpting**: starting with a lump of raw data, using hands-on techniques like shaping, molding, throwing, turning to give it form, applying digital techniques like data cleaning, filtering, grouping, extracting, then baking to yield the final form?

Each metaphor unlocks different ways of thinking. Each suggests different tools, different communities, different values. Ursula K. Le Guin invited us to see technology development as a [carrier bag rather than a weapon](https://theanarchistlibrary.org/mirror/u/uk/ursula-k-le-guin-the-carrier-bag-theory-of-fiction.pdf). I want to extend that invitation to programming itself.

## A Different Vision

I've started research at the Media Lab with a vision to create a new programming paradigm that reflects my beliefs about programming as art and craft, and the practice of which should lead to personal growth and community building. I started with a vague feeling in "[The Last of Programmers, the First of Artists](https://stackdiver.com/posts/the-last-of-programmers-the-first-of-artists/)." I want to bring new perspectives to clarify:

From **learning science**: revisiting constructivist learning, asking how we use language as a tool to encourage learning, and specifically why there's so little research interest in adult learning.

From **linguistics**: examining the purpose of programming languages and natural languages, exploring their synergy.

From **technical** perspectives: understanding properties of LLMs (fuzzy, probabilistic, associative through embeddings, contextual) and elements of programming language design (syntax, semantics).

From **philosophy**: questioning the purpose of programming (simulation, expression, existence), considering individuation, examining human conditions and whether our happiness is rooted in our ability to create.

## The Porcelain to Come

Alan Kay wrote in his 1984 [article on computer software](https://worrydream.com/refs/Kay_1984_-_Computer_Software.pdf):

> It is software that gives form and purpose to a programmable machine, much as a sculptor shapes clay.

He also emphasized that learning programming is not merely mastering the medium, but embodying hope:

> Hence the task for someone who wants to understand software is not simply to see the pot instead of the clay. It is to see in pots thrown by beginners [...] the possibility of the Chinese porcelain and Limoges to come.

Generative AI can become the clay for people to shape their ideas. And perhaps we already have a new fabric in hand with which our civilization can come together to embody our most beautiful dreams. I urge you to consider that programming itself _is_ the generative medium for every possible futures we desire. It's on us to preserve the craft of programming and to save the futures from the capitalistic pursuit of efficiency. I can't wait to see the Chinese porcelain and Limoges to come.

![Porcelain vase](https://upload.wikimedia.org/wikipedia/commons/3/31/Clevelandart_1962.154.jpg)
_Yuan Dynasty porcelain vase, c. 1300 ([source](https://en.wikipedia.org/wiki/Chinese_ceramics#/media/File:Clevelandart_1962.154.jpg))_
